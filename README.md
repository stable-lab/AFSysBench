# AFSysBench - AlphaFold 3 System Benchmarking

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![AlphaFold 3](https://img.shields.io/badge/AlphaFold-3-green.svg)](https://github.com/google-deepmind/alphafold3)

A systematic benchmarking suite for evaluating [AlphaFold 3](https://github.com/google-deepmind/alphafold3) performance across different hardware configurations. **No external Python dependencies required!**

## ğŸš€ Key Features

- **Modular Architecture** - Clean separation between MSA and inference benchmarking
- **Unified Memory Support** - Run large structures (e.g., 6QNR) on consumer GPUs
- **Multi-threading Analysis** - Test performance across thread configurations
- **Hardware Profiling** - Built-in support for NVIDIA Nsight, Linux perf, and custom profilers
- **Real-time Monitoring** - Live system resource monitoring with `monitor_realtime.sh`
- **NUMA Profiling** - Advanced NUMA and PCM performance analysis
- **Automated Results** - CSV generation with master results tracking
- **Docker Integration** - Consistent environment across systems

## ğŸ“Š Proven Performance

Successfully tested on:

**Server System:**
- **Intel Xeon + H100 (80GB)** - Full benchmark suite without unified memory
- **Server-grade performance** - Optimal for large structure analysis

**Desktop System:**  
- **AMD Ryzen 9 7900X + RTX 4080 (16GB)** - 6QNR inference in ~8 minutes with unified memory
- **Consumer-grade accessibility** - Efficient multi-threaded MSA performance

## ğŸƒ Quick Start

### Prerequisites

- **AlphaFold 3**: Official implementation from [google-deepmind/alphafold3](https://github.com/google-deepmind/alphafold3)
- **Hardware**: NVIDIA GPU (16GB+ VRAM), 64GB+ RAM, 3TB+ storage for databases
- **Software**: Docker 20.10+, CUDA 12.0+, Python 3.10+ (for AF3 compatibility)
- **No additional Python packages needed** for benchmarking - uses only standard library!

### Installation

1. Clone the repository:
```bash
git clone https://github.com/stable-lab/AFSysBench.git
cd AFSysBench
```

2. Configure your system:
```bash
cp benchmark.config.template benchmark.config
# Edit benchmark.config with your AF3 paths
```

3. Quick test (5-7 minutes):
```bash
# Test complete pipeline: MSA + Inference
python runner -c benchmark.config msa -i 2PV7.json -t 1
python runner -c benchmark.config inference -i 2pv7_data.json -t 1

# Success = structure files created in results/
```

### For Large Structures (Unified Memory)

```bash
# Edit your config file
nano benchmark.config
# Set: ENABLE_UNIFIED_MEMORY=true

# Run 6QNR on RTX 4080
python runner -c benchmark.config inference -i 6QNR_subset_data.json -t 1
```

## ğŸ“– Documentation

- [Installation Guide](INSTALL.md) - Detailed setup instructions
- [Reproduction Guide](REPRODUCE.md) - Reproduce paper results
- [Configuration Reference](docs/guides/configuration.md)
- [Unified Memory Guide](docs/guides/unified_memory.md)
- [Examples](docs/examples/README.md)

## ğŸ—ï¸ Architecture

```
AFSysBench/
â”œâ”€â”€ runner                           # Main Python orchestrator (executable)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ benchmark_msa_modular.sh    # MSA benchmarking logic
â”‚   â”œâ”€â”€ benchmark_inference_modular.sh # Inference benchmarking
â”‚   â”œâ”€â”€ profiling_runner.sh         # Profiling orchestrator
â”‚   â””â”€â”€ result_collector.sh         # Results aggregation
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ config.sh                   # Configuration management
â”‚   â”œâ”€â”€ docker_utils.sh             # Docker management
â”‚   â”œâ”€â”€ gpu_memory_manager.py       # GPU memory management
â”‚   â”œâ”€â”€ logging.sh                  # Logging utilities
â”‚   â”œâ”€â”€ monitoring.sh               # System monitoring
â”‚   â”œâ”€â”€ result_parser.sh            # Result parsing and analysis
â”‚   â””â”€â”€ validation.sh               # System validation
â”œâ”€â”€ input_msa/                      # MSA input files
â”œâ”€â”€ input_inference/                # Inference input files
â”œâ”€â”€ output_msa/                     # MSA benchmark results (generated)
â”œâ”€â”€ output_inference/               # Inference benchmark results (generated)
â”œâ”€â”€ results/                        # Aggregated benchmark results
â”œâ”€â”€ monitor_realtime.sh             # Real-time system monitoring
â”œâ”€â”€ run_statistical_benchmarks.sh   # Comprehensive statistical analysis
â”œâ”€â”€ run_inference_perf.sh           # Performance benchmarking
â”œâ”€â”€ run_numa_pcm_profiling.sh       # NUMA/PCM profiling
â”œâ”€â”€ run_full_msa_validation.sh      # MSA validation suite
â””â”€â”€ docs/                           # Documentation
```

## ğŸ”¬ Usage Examples

### Basic Benchmarking
```bash
# Run MSA benchmark
python runner -c benchmark.config msa -i rcsb_pdb_7RCE.json -t 8

# Run inference benchmark
python runner -c benchmark.config inference -i 1yy9_data.json -t 4

# Run with profiling
python runner -c benchmark.config profile -i 1yy9_data.json -p nsys -s inference
```

### Monitoring and Profiling
```bash
# Real-time system monitoring
./monitor_realtime.sh

# NUMA and PCM profiling
./run_numa_pcm_profiling.sh myenv.config 2pv7_data.json

# Performance inference benchmarking
./run_inference_perf.sh myenv.config

# Track progress of running jobs
python track_progress.py --config myenv.config --job-id inference_2024
```

### Large Structure Processing
```bash
# Edit config file to enable unified memory
nano benchmark.config
# Set: ENABLE_UNIFIED_MEMORY=true

python runner -c benchmark.config inference -i 6QNR_subset_data.json -t 1
```

## ğŸ“ˆ Results

Results are automatically saved in CSV format:
- `results/master_results.csv` - Consolidated benchmark data
- `output_*/results_*.csv` - Individual run results
- `output_*/gpu_monitoring.csv` - GPU utilization metrics

## ğŸ› ï¸ Configuration

Key configuration options in your config file:

```bash
# System Information
SYSTEM_NAME="my_system"
SYSTEM_TYPE="workstation"  # or "gpu"

# Paths
DB_DIR="/path/to/alphafold/databases"
MODEL_DIR="/path/to/alphafold/models"

# Memory Settings
UNIFIED_MEMORY=true  # Enable for large structures on limited GPU memory

# Benchmark Settings
THREAD_COUNTS="1 2 4 6 8"
```

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [AlphaFold 3 team at Google DeepMind](https://github.com/google-deepmind/alphafold3)
- NVIDIA for unified memory support
- Contributors and testers

## ğŸ“š Citation

If you use AFSysBench in your research, please cite:

```bibtex
@misc{afsysbench2025,
  title={AFSysBench: Systematic Benchmarking of AlphaFold 3 for Optimized Deployment},
  author={[To be updated]},
  year={2024},
  note={Manuscript in preparation. Citation details will be updated upon publication.}
}
```

*Note: This work is currently under review. Full citation details will be provided upon publication.*

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/stable-lab/AFSysBench/issues)
- **Discussions**: [GitHub Discussions](https://github.com/stable-lab/AFSysBench/discussions)

---
*AFSysBench - Benchmarking AlphaFold 3 for the scientific community*
